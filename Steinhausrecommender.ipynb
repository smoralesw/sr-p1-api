{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae3aed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import time\n",
    "import umap\n",
    "import paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf99d3",
   "metadata": {},
   "source": [
    "## FLUJO:\n",
    "\n",
    "### Procesamiento\n",
    "\n",
    "Inputs: \n",
    "        Dataframe de interacción (Playlists, id)\n",
    "        Dataframe de información (id, nombre)\n",
    "Procesamiento:\n",
    "        Usando las funciones de sampleo se samplean las interacciones con muchos o muy pocos elementos (sample middle users)\n",
    "        Posteriormente se samplean las interacciones que solo contienen elementos con muchas o muy pocas interacciones(Sample middle elements)\n",
    "        El proceso se encuentra empaquetado en la función particular elements sample, que retorna el diccionario elements_map\n",
    "        keys: elementos\n",
    "        Values: Usuarios que lo evaluaron bien (playlists que contienen la canción)\n",
    "\n",
    "### Construcción de grafo\n",
    "\n",
    "La clase Cover contiene todos los elementos para realizar la filtración de Steinhaus:\n",
    "    Las coberturas serán el diccionario elements_map, es decir, la cobertura de un elemento será el conjunto de usuarios que evaluo bien el elemento (la cobertura de la canción es el conjunto de elemento que los contiene)\n",
    "    La distancia entre dos elementos es la distacia de Jaccard de las coberturas\n",
    "    Este proceso esta empaquetado en el método build que retorna los simplices (conjuntos de conjuntos de elementos con la distancia de sus coberturas entre ellos)\n",
    "    \n",
    "Finalmente el grafo se construye con la función Build Graph:\n",
    "    La distancia entre los elementos (tiempo que tardan en aparecer en la filtración) será el valor de las aristas\n",
    "    El id de los elementos serán nodos\n",
    "    \n",
    "### Procesamiento de caminos\n",
    "\n",
    "Esto se encuentra en el módulo Paths, particularmente la función most_stable. En utils se encuentran las funciones elements_name_in_path y print, que buscan pasar los id a nombres de elemento en base al dataframe de información\n",
    "\n",
    "### Loaders\n",
    "\n",
    "Se agregan funciones utilizadas para cargar los dataframes utilizados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0aecd",
   "metadata": {},
   "source": [
    "## Steinhaus Filtration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcf022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from cechmate import Cover\n",
    "class BaseFiltration:\n",
    "    def __init__(self, max_dim=3):\n",
    "        \n",
    "        self.max_dim = max_dim\n",
    "        \n",
    "        \n",
    "class Cover(BaseFiltration):\n",
    "    \"\"\"\n",
    "    Class that make the filtration for the graph\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_dim):\n",
    "        \"\"\"\n",
    "        max_dim: max dim of simplices \n",
    "        \"\"\"\n",
    "        super().__init__(max_dim)\n",
    "        self.covers = None\n",
    "        self.simplices = None\n",
    "        self.dists = []  \n",
    "    \n",
    "    def build(self, covers: dict):\n",
    "        \"\"\"\n",
    "        Input: Dictionary of element and its covers (user that rated positively the element)\n",
    "        Returns: Simplices\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # Give each cover element a name.\n",
    "        if not isinstance(covers, dict):\n",
    "            covers = dict(enumerate(covers))\n",
    "            \n",
    "        simplices = [([k], 0.0) for k in covers.keys()]\n",
    "        \n",
    "        # TODO: be more intelligent about which combos we check\n",
    "\n",
    "        #Changed self.max_dim+1 to self.max_dim+2. Correct?\n",
    "        for k in range(2, self.max_dim + 2):\n",
    "            for potentials in itertools.combinations(covers.keys(), k):\n",
    "                potential_sets = [covers[p] for p in potentials]\n",
    "\n",
    "                d = self.jaccard(potential_sets)\n",
    "                self.dists.append(d)\n",
    "\n",
    "                # TODO: Do we want to include all of these simplices as well?\n",
    "                if d < 1:\n",
    "                    simplices.append((potentials, d))\n",
    "        \n",
    "        self.covers = covers\n",
    "        self.simplices = simplices\n",
    "        self.d = d\n",
    "        \n",
    "        return simplices\n",
    "\n",
    "    def jaccard(self, covers):\n",
    "        \"\"\"\n",
    "        Input: covers\n",
    "        Returns: Jaccard Distance between covers\n",
    "        \"\"\"\n",
    "        \n",
    "        covers_as_sets = list(map(set, covers))\n",
    "        intersection = set.intersection(*covers_as_sets)\n",
    "        union = set.union(*covers_as_sets)\n",
    "\n",
    "        return 1 - len(intersection) / len(union)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd70e6c",
   "metadata": {},
   "source": [
    "## Sample of interaction matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0174b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_middle_elements(ratings: np.ndarray, lower=0.5, upper=0.95):\n",
    "    \"\"\" \n",
    "    \n",
    "    Sample just given percentiles of elements\n",
    "    Input: User interaction Matrix (binary)\n",
    "    \n",
    "    \"\"\"\n",
    "    movies = ratings.groupby('id')\n",
    "    movies_map = {name: list(group.pid) for name, group in movies}\n",
    "\n",
    "    movies_ratings_n = [len(m) for m in movies_map.values()]\n",
    "    lower_bound, upper_bound = pd.Series(movies_ratings_n).quantile([lower, upper]).values\n",
    "    print(f\"Remove movies with # ratings <= {lower_bound} and # ratings >= {upper_bound}\")\n",
    "\n",
    "    movies_map = {name: mlist for name, mlist in movies_map.items() if lower_bound <= len(mlist) <= upper_bound}\n",
    "    print(f\"Was {len(movies_ratings_n)}, now {len(movies_map)} movies in the range.\")\n",
    "    \n",
    "    return movies_map\n",
    "\n",
    "def sample_middle_users(ratings:np.ndarray, lower=0.6, upper=0.95):\n",
    "    \"\"\" \n",
    "    \n",
    "    sample middle given percentiles of users\n",
    "    Input: User interaction Matrix (binary)\n",
    "    \n",
    "    \"\"\"\n",
    "    users = ratings.groupby('pid')\n",
    "    users_map = {name: list(group.id) for name, group in users}\n",
    "\n",
    "    users_ratings_n = [len(m) for m in users_map.values()]\n",
    "    lower_bound, upper_bound = pd.Series(users_ratings_n).quantile([lower, upper]).values\n",
    "    print(f\"Remove movies with # ratings <= {lower_bound} and # ratings >= {upper_bound}\")\n",
    "\n",
    "    users_map = {name: ulist for name, ulist in users_map.items() if lower_bound <= len(ulist) <= upper_bound}\n",
    "    print(f\"Was {len(users_ratings_n)}, now {len(users_map)} users in the range.\")\n",
    "    \n",
    "    return users_map\n",
    "\n",
    "def particular_elements_sample(ratings: np.ndarray, elements_info:pd.DataFrame, \n",
    "                               genre_to_use = 'hard rock', n=15000, sample = True, genre = True, ):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Sample and filter the elements to use to ~n\n",
    "    Ratings: User interaction Matrix (binary)\n",
    "    Elements_info: Information about elements dataframe (genre, name, etc)\n",
    "                   Needs to contain id element amd genre element to filter by genre\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # limit to only middle percentile users \n",
    "    users_map = sample_middle_users(ratings)\n",
    "    ok_users = list(users_map.keys())\n",
    "    sub_ratings = ratings[(ratings['id'].isin(ok_users))]\n",
    "    \n",
    "    # Filter only particular movies\n",
    "    print(f\"--{len(sub_ratings)} movie reviews after filtering users\")\n",
    "    sub_ratings = sub_ratings[sub_ratings['id'].isin(elements_info.id)]\n",
    "    print(f\"--{len(sub_ratings)} movie reviews after filtering good movies\")\n",
    "    \n",
    "    # Get movies with middle percentiles          \n",
    "    movies_map = sample_middle_movies(sub_ratings)\n",
    "    print(len(movies_map))\n",
    "    print(\"Sample movies\")\n",
    "\n",
    "    # then randomly sample the movies\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    \n",
    "    movies_map = {name: list(group.pid) for name, group in movies}\n",
    "    movies_ratings_n = [len(m) for m in movies_map.values()]\n",
    "    \n",
    "    if genre == True:\n",
    "        \n",
    "        mask = elements_info.loc[elements_info.genres.str.contains(genre_to_use)]\n",
    "        \n",
    "        movies_map = {m:l for m,l in movies_map.items() \n",
    "                     if m in mask['id'].values}\n",
    "    if sample == True:   \n",
    "        rate = n / len(movies_map)\n",
    "        print(rate)\n",
    "        \n",
    "        movies_map = {m:l for m,l in movies_map.items() if np.random.random() <= rate}\n",
    "    #or name in good_movies\n",
    "    print(f\"Resulting dataset has {len(movies_map)} movies\")\n",
    "    return movies_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c43d0",
   "metadata": {},
   "source": [
    "## Graph generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_filt(filtration, thresh):\n",
    "    filtration = [f for f in filtration if f[1] < thresh]\n",
    "    return filtration\n",
    "    \n",
    "def build_graph(filtration, thresh=None):\n",
    "    \"\"\" Build a networkx graph out of the 1-skeleton in the filtration\n",
    "    \"\"\"\n",
    "    if thresh:\n",
    "        filtration = thresh_filt(filtration, thresh)\n",
    "    vertices = [s[0][0] for s in filtration if len(s[0]) == 1]\n",
    "    edges = [s[0] for s in filtration if len(s[0]) == 2]\n",
    "    edge_attrs = {s[0]: s[1] for s in filtration if len(s[0]) == 2}\n",
    "    edge_weights = list(edge_attrs.values())\n",
    "    \n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(vertices)\n",
    "    g.add_edges_from(edges)\n",
    "    nx.set_edge_attributes(g, edge_attrs, 'dist')\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11771",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pareto2(most_stable, all_stable_paths, save=False):\n",
    "    \n",
    "    # stabs = [p[1] for p in most_stable.values()]\n",
    "    # lens = list(most_stable.keys())\n",
    "        \n",
    "    unoptimal_paths = np.array([(n, s[1]) for n, ps in all_stable_paths.items() for s in ps])\n",
    "    optimal_paths = np.array([(n,ps[1]) for n, ps in most_stable.items()])\n",
    "\n",
    "    ax = plt.figure(figsize=(20,10)).gca()  \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True)) \n",
    "    plt.subplot(111)\n",
    "    \n",
    "    matplotlib.rc('xtick', labelsize=20) \n",
    "    matplotlib.rc('ytick', labelsize=20) \n",
    "\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    plt.scatter(unoptimal_paths[:,0], unoptimal_paths[:,1], color=cmap(1), label='Nonoptimal paths')\n",
    "    plt.scatter(optimal_paths[:,0], optimal_paths[:,1], label='Optimal paths')\n",
    "    plt.plot(optimal_paths[:,0], optimal_paths[:,1], label='Pareto frontier')\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Length of path\")\n",
    "    plt.ylabel(\"Instability of path\")\n",
    "\n",
    "    plt.legend()\n",
    "    ticks = range(int(min(optimal_paths[:,0])), int(max(optimal_paths[:,0])) + 1)\n",
    "    plt.xticks(ticks)\n",
    "    if save!=False:\n",
    "        plt.savefig(save,)\n",
    "        \n",
    "        \n",
    "def element_names_in_path(ms, elements_info):\n",
    "    \"\"\"\n",
    "    Returns names of elements of most stable paths\n",
    "    ms: Most stable paths list\n",
    "    \"\"\"\n",
    "    elements_in_path = ms[0]\n",
    "    pms = [elements_info.loc[elements_info.id == m].track_name.values[0] for m in elements_in_path]\n",
    "    return pms\n",
    "\n",
    "\n",
    "def print_names_in_path(pms):\n",
    "    for i in pms.keys()\n",
    "    print(\"\\n {0} elements path: \\n\".format(i))\n",
    "    print(\"\\n\".join(element_names_in_path(most_stable[i])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41cad1d",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(path, csv):\n",
    "    \"\"\"Load and preprocess ratings dataframe (interaction matrix)\"\"\"\n",
    "    ratings = pd.read_csv(os.path.join(path, csv), delimiter=\",\")\n",
    "    ratings = ratings.drop(columns = 'Unnamed: 0')\n",
    "    return ratings\n",
    "\n",
    "def load_info(path, csv):\n",
    "    \"\"\"Load and preprocess information dataframe \"\"\"\n",
    "    info = pd.read_csv(os.path.join(path_to_ml_20m, csv), delimiter=\",\")\n",
    "    info = info.dropna()\n",
    "    info = info.drop(columns = 'id.1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
